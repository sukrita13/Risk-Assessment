{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8099d5d8-e1d8-425d-8199-65b32ed26b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea69efb-e17e-4d89-b280-914003313af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# define filepath to read data\n",
    "dir_path = 'data/Surgical_data/'\n",
    "# Randomized Seed\n",
    "seed = 123\n",
    "# Testing Set Proportion\n",
    "test_proportion = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca0de86-193a-4740-abfe-3eb6509e09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv((dir_path+'Surgical-deepnet.csv'), sep =  \",\",na_values=\"?\")\n",
    "#Turn the outcome into an independent vector\n",
    "y_data = data.pop('complication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6e5a01-7265-4430-8f94-39ada2f01f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10945\n",
       "1     3690\n",
       "Name: complication, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493a9015-09f9-40fd-aac8-d4fa616455e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between training and testing set\n",
    "X_train_inc_cal, X_test, y_train_inc_cal, y_test = train_test_split(data, y_data, test_size = test_proportion, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb937408-932c-4208-b722-f221741027e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between training and calibration set\n",
    "X_train, X_cal, y_train, y_cal = train_test_split(X_train_inc_cal, y_train_inc_cal, test_size = 0.5, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6071f3d1-339f-422a-a91c-cf3aeb8c440d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train the classifier\n",
    "# clf = RandomForestClassifier() \n",
    "\n",
    "# param_grid = {'n_estimators': [100, 200, 250, 500, 750, 1000],\n",
    "#                  'max_depth': [2, 3, 4, 5, 6, 7, 10, 15]\n",
    "#              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b5e98f-cf55-4085-8456-6d44c7e35b50",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10-Fold Cross validation\n",
    "# grid_clf = GridSearchCV(clf, param_grid, cv=10)\n",
    "# grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da8ad46-1343-4d92-883a-1387ed324b89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score = grid_clf.score(X_test, y_test) \n",
    "# print(score)\n",
    "\n",
    "# y_hat_test = grid_clf.predict(X_test)\n",
    "# cm = metrics.confusion_matrix(y_test, y_hat_test)\n",
    "# print(cm)\n",
    "\n",
    "# #Seaborn Matrix\n",
    "# plt.figure(figsize=(9,9))\n",
    "# sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "# plt.ylabel('Actual label');\n",
    "# plt.xlabel('Predicted label');\n",
    "# all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "# plt.title(all_sample_title, size = 15); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b718a55e-e25d-4c9c-8e57-119cd655d73d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Output probabilities\n",
    "# y_proba_hat_train = grid_clf.predict_proba(X_train)\n",
    "# y_proba_hat_cal = grid_clf.predict_proba(X_cal)\n",
    "# y_proba_hat_test = grid_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45df64cf-64e1-4041-aca8-b0006c840598",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_col_names = ['proba_0','proba_1']\n",
    "\n",
    "# X_train['y'] = pd.Series(y_train)\n",
    "# X_cal['y'] = pd.Series(y_cal)\n",
    "# X_test['y'] = pd.Series(y_test)\n",
    "\n",
    "# X_train[new_col_names] = pd.DataFrame(y_proba_hat_train).set_index(X_train.index)\n",
    "# X_cal[new_col_names] = pd.DataFrame(y_proba_hat_cal).set_index(X_cal.index)\n",
    "# X_test[new_col_names] = pd.DataFrame(y_proba_hat_test).set_index(X_test.index)\n",
    "\n",
    "# X_train.to_csv(dir_path+'Surgical_data_train_processed_seed_'+str(seed)+'.csv')\n",
    "# X_cal.to_csv(dir_path+'Surgical_data_cal_processed_seed_'+str(seed)+'.csv')\n",
    "# X_test.to_csv(dir_path+'Surgical_data_test_processed_seed_'+str(seed)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da260d-b3bf-44ce-9bc5-eb7b91550bbe",
   "metadata": {},
   "source": [
    "### Conformal risk control setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024b283e-5c58-4bb7-b48d-0bd4c53b2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(dir_path + 'Surgical_data_train_processed_seed_' + str(seed) + '.csv', index_col=0)\n",
    "X_cal = pd.read_csv(dir_path + 'Surgical_data_cal_processed_seed_' + str(seed) + '.csv', index_col=0)\n",
    "X_test = pd.read_csv(dir_path + 'Surgical_data_test_processed_seed_' + str(seed) + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663ff6ac-b399-4dbb-bd36-aa52a1c0b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n = len(X_cal) # number of calibration points\n",
    "alpha = 0.1 # 1-alpha is the desired false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f29933b-f8af-4c02-a8d1-2bda56359bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def risk_metrics(y_pred, y_true):\n",
    "    FP = np.logical_and(y_true != y_pred, y_true == 0).sum()  \n",
    "    FN = np.logical_and(y_true != y_pred, y_true == 1).sum()  \n",
    "    TP = np.logical_and(y_true == y_pred, y_true == 1).sum()  \n",
    "    TN = np.logical_and(y_true == y_pred, y_true == 0).sum()  \n",
    "    \n",
    "    FNR = 1. * FN/(TP + FN)  \n",
    "    FPR = 1. * FP/(FP + TN)  \n",
    "    \n",
    "    return pd.DataFrame([FNR, FPR]).T.rename(columns = {0:'FNR', 1:'FPR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7528bbdd-373e-46c5-a094-b1cde9ee632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration and validation sets \n",
    "cal_sgmd = X_cal['proba_1']\n",
    "test_sgmd = X_test['proba_1']\n",
    "cal_gt = X_cal['y']\n",
    "test_gt = X_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "562effbc-8ae1-4c7a-ab7b-995247956a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5488,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_sgmd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1992b1a-71a7-46e0-8f41-ec24432e7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conformal risk control procedure\n",
    "def lamhat_threshold(risk_type, lam): \n",
    "    risk_metric = risk_metrics(cal_sgmd >= lam, cal_gt)[risk_type]\n",
    "    return risk_metric - ((n+1)/n*alpha - 1/(n+1)) ###is 1/(n+1) an error ? not that it will matter much\n",
    "\n",
    "lamhat = brentq(lambda lam: lamhat_threshold('FNR', lam), 0, 1)\n",
    "y_test_pred = test_sgmd >= lamhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82e52d96-8779-44db-bb6a-935df36e9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical FNR is: 0.12665198237885464 and the threshold value is: 0.19448080741201598\n"
     ]
    }
   ],
   "source": [
    "# Calculate empirical FNR\n",
    "print(f\"The empirical FNR is: {risk_metrics(y_test_pred, test_gt)['FNR'][0]} and the threshold value is: {lamhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56dafc-ef69-4401-a100-411f07b1b55d",
   "metadata": {},
   "source": [
    "### Inverse CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eca289b-4652-422e-9229-0bbd747b25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fada1cf-cb1f-4323-a557-90943a85a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphahat_threshold(risk_type, alpha): \n",
    "    risk_metric = risk_metrics(cal_sgmd >= lam, cal_gt)[risk_type]\n",
    "    return risk_metric - ((n+1)/n*alpha - 1/(n+1)) \n",
    "\n",
    "alphahat_FNR = brentq(lambda alpha: alphahat_threshold('FNR', alpha), 0, 1)\n",
    "alphahat_FPR = brentq(lambda alpha: alphahat_threshold('FPR', alpha), 0, 1)\n",
    "y_test_pred = test_sgmd >= lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51fb50bd-accf-46da-9c36-004e4605d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical FNR: 0.13105726872246695\n",
      "Empirical FPR: 0.29225736095965105\n",
      "FNR alpha estimate: 0.10553629481031597\n",
      "FNR alpha estimate: 0.29408667177420744\n"
     ]
    }
   ],
   "source": [
    "# Calculate empirical FNR\n",
    "print(f\"Empirical FNR: {risk_metrics(y_test_pred, test_gt)['FNR'][0]}\")\n",
    "print(f\"Empirical FPR: {risk_metrics(y_test_pred, test_gt)['FPR'][0]}\")\n",
    "print(f\"FNR alpha estimate: {alphahat_FNR}\")\n",
    "print(f\"FNR alpha estimate: {alphahat_FPR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd63bb-1f78-473f-8a2c-b1cf00839bbf",
   "metadata": {},
   "source": [
    "### LTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4164cd39-593d-4fdf-a59d-3733f3afa357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16716716716716717"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "delta = 0.01\n",
    "lambdas = np.linspace(0,1,N) # Commonly choose N = 1000\n",
    "FNR = np.zeros(N)\n",
    "FPR = np.zeros(N)# Compute the loss function next\n",
    "\n",
    "for i in range(N):\n",
    "    FNR[i] = risk_metrics(cal_sgmd >= lambdas[i], cal_gt)['FNR']\n",
    "    FPR[i] = risk_metrics(cal_sgmd >= lambdas[i], cal_gt)['FPR']\n",
    "    \n",
    "risk = FNR\n",
    "pvals = np.exp(-2*n*(np.maximum(0.0, alpha - risk)**2)) # Or any p-value\n",
    "lambda_hat = lambdas[pvals < delta/lambdas.shape[0]]\n",
    "lambda_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6142e41-868a-44fd-b3cc-80b1cde9c6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5488"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26374ace-24d2-4b6d-a889-c343c9acf70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.147027792703121e-48"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-2*n*(np.maximum(0.0, alpha - min(risk))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e2f3f-1b90-40ff-9b80-c026e54eadeb",
   "metadata": {},
   "source": [
    "### Inverse LTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ceea90e-ec37-45b8-924f-930c52909d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24df78e9-bee6-4384-9304-439da62f11b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4034034034034034, 0.0980980980980981)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "delta = 0.01\n",
    "alpha_space = np.linspace(0,1,N) # Commonly choose N = 1000\n",
    "pvals_FNR = np.zeros(N)\n",
    "pvals_FPR = np.zeros(N)# Compute the loss function next\n",
    "\n",
    "FNR = risk_metrics(cal_sgmd >= lam, cal_gt)['FNR']\n",
    "FPR = risk_metrics(cal_sgmd >= lam, cal_gt)['FPR']\n",
    "    \n",
    "for i in range(N):\n",
    "    pvals_FNR[i] = np.exp(-2*n*(np.maximum(0.0, alpha_space[i] - FNR)**2)) # Or any p-value\n",
    "    pvals_FPR[i] = np.exp(-2*n*(np.maximum(0.0, alpha_space[i] - FPR)**2)) # Or any p-value\n",
    "    \n",
    "alpha_hat_FNR = alpha_space[pvals_FNR < delta/alpha_space.shape[0]]\n",
    "alpha_hat_FPR = alpha_space[pvals_FPR < delta/alpha_space.shape[0]]\n",
    "\n",
    "alpha_hat_FPR.min(), alpha_hat_FNR.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
